CubeAdjMtxReconstructor: !hcv
  help: The model to reconstruct the cube adjacency matrix
  value: !hc
    TransformSingleCard: !hcv
      help: The MLP layer that tries to reconstruct the adjacency matrix row for the
        single card cube
      value: !hc
        Dropout: !hcv
          help: The dropout applied after each hidden layer.
          value: !hc
            rate: !hcv
              help: The percent of values that get replaced with zero.
              value: 0.2
        Final: !hcv
          help: The last dense layer in the MLP.
          value: !hc
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        Hidden_0: !hcv
          help: The 1st hidden layer.
          value: !hc
            activation: !hcv
              choices: &id001 !!python/tuple
              - elu
              - selu
              - relu
              - tanh
              - sigmoid
              - linear
              - swish
              help: The activation function on the output of the layer.
              value: selu
            dims: !hcv
              help: The number of dimensions in the output of this layer.
              value: 128
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        num_hidden: !hcv
          help: The number of hidden layers in the MLP.
          value: 1
    temperature_reg_weight: !hcv
      help: The amount to scale the squared temperature by for loss.
      value: 0.01
CubeRecommender: !hcv
  help: The model for the draftbots
  value: !hc
    EmbedCube: !hcv
      help: Combine the card embeddings to get an embedding for the cube.
      value: !hc
        Decoder: !hcv
          help: The mapping from the added item embeddings to the embeddings to return.
          value: !hc
            Final: !hcv
              help: The last dense layer in the MLP.
              value: !hc
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            Hidden_0: !hcv
              help: The 1st hidden layer.
              value: !hc
                activation: !hcv
                  choices: *id001
                  help: The activation function on the output of the layer.
                  value: selu
                dims: !hcv
                  help: The number of dimensions in the output of this layer.
                  value: 128
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            Hidden_1: !hcv
              help: The 1st hidden layer.
              value: !hc
                activation: !hcv
                  choices: *id001
                  help: The activation function on the output of the layer.
                  value: selu
                dims: !hcv
                  help: The number of dimensions in the output of this layer.
                  value: 256
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            num_hidden: !hcv
              help: The number of hidden layers in the MLP.
              value: 2
        Encoder: !hcv
          help: The layers to model interactions between items.
          value: !hc
            Transformer_0: !hcv
              help: The 0th transformer layer.
              value: !hc
                FinalMLP: !hcv
                  help: The final transformation.
                  value: !hc
                    Final: !hcv
                      help: The last dense layer in the MLP.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 64
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_0: !hcv
                      help: The 1st hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 128
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_1: !hcv
                      help: The 2nd hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 256
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
            Transformer_1: !hcv
              help: The 1th transformer layer.
              value: !hc
                FinalMLP: !hcv
                  help: The final transformation.
                  value: !hc
                    Final: !hcv
                      help: The last dense layer in the MLP.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 64
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_0: !hcv
                      help: The 1st hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 128
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_1: !hcv
                      help: The 2nd hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 256
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
            Transformer_2: !hcv
              help: The 2th transformer layer.
              value: !hc
                FinalMLP: !hcv
                  help: The final transformation.
                  value: !hc
                    Final: !hcv
                      help: The last dense layer in the MLP.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 64
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_0: !hcv
                      help: The 1st hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 128
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_1: !hcv
                      help: The 2nd hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 256
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
            activation: !hcv
              choices: *id001
              help: The activation function on the output of the layer.
              value: selu
            attention dropout_rate: !hcv
              help: The dropout rate for the attention layers of the transformer blocks.
              value: 0
            dense dropout_rate: !hcv
              help: The dropout rate for the dense layers of the transformer blocks.
              value: 0.1
            dims: !hcv
              help: The number of dimensions for the output.
              value: 64
            key_dims: !hcv
              help: Size of the attention head for query and key.
              value: 32
            num_heads: !hcv
              help: The number of separate heads of attention to use.
              value: 4
            num_hidden_dense: !hcv
              help: The number of hidden dense layers
              value: 2
            num_hidden_layers: !hcv
              help: Number of transformer blocks.
              value: 2
            output_dims: !hcv
              help: The number of output dimensions from this layer.
              value: 512
            use_bias: !hcv
              help: Use bias in the dense layers
              value: true
            value_dims: !hcv
              help: Size of the attention head for value.
              value: 32
        ItemDropout: !hcv
          help: Drops out entire items from the set.
          value: !hc
            rate: !hcv
              help: The percent of values that get replaced with zero.
              value: 0.2
        Pooling: !hcv
          help: The layer to collapse down to one embedding.
          value: !hc
            Attention: !hcv
              help: The attention layer that pools the results.
              value: !hc
                dropout: !hcv
                  help: The percent of values to get dropped out
                  value: 0.25
                key_dims: !hcv
                  help: Size of the attention head for query and key.
                  value: 8
                num_heads: !hcv
                  help: The number of separate heads of attention to use.
                  value: 8
                output_dims: !hcv
                  help: The number of output dimensions from this layer.
                  value: 64
                use_bias: !hcv
                  help: Use bias in the dense layers
                  value: true
                value_dims: !hcv
                  help: Size of the attention head for value.
                  value: 4
        decoding_dropout_rate: !hcv
          help: The percent of values to dropout from the result of dense layers in
            the decoding step.
          value: 0.1
    TransformCards: !hcv
      help: Transform card embeddings to a different orientation
      value: !hc
        Dropout: !hcv
          help: The dropout applied after each hidden layer.
          value: !hc
            rate: !hcv
              help: The percent of values that get replaced with zero.
              value: 0.2
        Final: !hcv
          help: The last dense layer in the MLP.
          value: !hc
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        Hidden_0: !hcv
          help: The 1st hidden layer.
          value: !hc
            activation: !hcv
              choices: *id001
              help: The activation function on the output of the layer.
              value: selu
            dims: !hcv
              help: The number of dimensions in the output of this layer.
              value: 128
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        num_hidden: !hcv
          help: The number of hidden layers in the MLP.
          value: 1
    embed_dims: !hcv
      help: The number of dimensions for similarity comparisons
      value: 256
    scale_relevant_cards: !hcv
      help: The amount to scale the loss on the cards in the noisy cube and the true
        cube.
      value: 5
    temperature_reg_weight: !hcv
      help: The amount to scale the squared temperature by for loss.
      value: 0.01
DeckAdjMtxReconstructor: !hcv
  help: The model to reconstruct the deck adjacency matrix
  value: !hc
    TransformSingleCard: !hcv
      help: The MLP layer that tries to reconstruct the adjacency matrix row for the
        single card cube
      value: !hc
        Dropout: !hcv
          help: The dropout applied after each hidden layer.
          value: !hc
            rate: !hcv
              help: The percent of values that get replaced with zero.
              value: 0.1
        Final: !hcv
          help: The last dense layer in the MLP.
          value: !hc
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        Hidden_0: !hcv
          help: The 1st hidden layer.
          value: !hc
            activation: !hcv
              choices: *id001
              help: The activation function on the output of the layer.
              value: selu
            dims: !hcv
              help: The number of dimensions in the output of this layer.
              value: 128
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        Hidden_1: !hcv
          help: The 1st hidden layer.
          value: !hc
            activation: !hcv
              choices: *id001
              help: The activation function on the output of the layer.
              value: selu
            dims: !hcv
              help: The number of dimensions in the output of this layer.
              value: 256
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        Hidden_2: !hcv
          help: The 1st hidden layer.
          value: !hc
            activation: !hcv
              choices: *id001
              help: The activation function on the output of the layer.
              value: selu
            dims: !hcv
              help: The number of dimensions in the output of this layer.
              value: 512
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        num_hidden: !hcv
          help: The number of hidden layers in the MLP.
          value: 3
    temperature_reg_weight: !hcv
      help: The amount to scale the squared temperature by for loss.
      value: 0.03
DraftBots: !hcv
  help: The model for the draftbots
  value: !hc
    CardRating: !hcv
      help: Translates embeddings into linear ratings.
      value: !hc
        Dropout: !hcv
          help: The dropout applied after each hidden layer.
          value: !hc
            rate: !hcv
              help: The percent of values that get replaced with zero.
              value: 0.2
        Final: !hcv
          help: The last dense layer in the MLP.
          value: !hc
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        Hidden_0: !hcv
          help: The 1st hidden layer.
          value: !hc
            activation: !hcv
              choices: *id001
              help: The activation function on the output of the layer.
              value: selu
            dims: !hcv
              help: The number of dimensions in the output of this layer.
              value: 128
            use_bias: !hcv
              help: Whether to use bias on the output.
              value: true
        num_hidden: !hcv
          help: The number of hidden layers in the MLP.
          value: 1
    EmbedPack: !hcv
      help: The layer that embeds the packs that have been seen so far.
      value: !hc
        Decoder: !hcv
          help: The mapping from the added item embeddings to the embeddings to return.
          value: !hc
            Final: !hcv
              help: The last dense layer in the MLP.
              value: !hc
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            Hidden_0: !hcv
              help: The 1st hidden layer.
              value: !hc
                activation: !hcv
                  choices: *id001
                  help: The activation function on the output of the layer.
                  value: selu
                dims: !hcv
                  help: The number of dimensions in the output of this layer.
                  value: 128
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            num_hidden: !hcv
              help: The number of hidden layers in the MLP.
              value: 1
        Encoder: !hcv
          help: The layers to model interactions between items.
          value: !hc
            Transformer_0: !hcv
              help: The 0th transformer layer.
              value: !hc
                FinalMLP: !hcv
                  help: The final transformation.
                  value: !hc
                    Final: !hcv
                      help: The last dense layer in the MLP.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 64
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_0: !hcv
                      help: The 1st hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 128
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_1: !hcv
                      help: The 2nd hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 256
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
            Transformer_1: !hcv
              help: The 1th transformer layer.
              value: !hc
                FinalMLP: !hcv
                  help: The final transformation.
                  value: !hc
                    Final: !hcv
                      help: The last dense layer in the MLP.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 64
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_0: !hcv
                      help: The 1st hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 128
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_1: !hcv
                      help: The 2nd hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 256
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
            Transformer_2: !hcv
              help: The 2th transformer layer.
              value: !hc
                FinalMLP: !hcv
                  help: The final transformation.
                  value: !hc
                    Final: !hcv
                      help: The last dense layer in the MLP.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 64
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_0: !hcv
                      help: The 1st hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 128
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
                    Hidden_1: !hcv
                      help: The 2nd hidden layer.
                      value: !hc
                        activation: !hcv
                          choices: *id001
                          help: The activation function on the output of the layer.
                          value: selu
                        dims: !hcv
                          help: The number of dimensions in the output of this layer.
                          value: 256
                        use_bias: !hcv
                          help: Whether to use bias on the output.
                          value: true
            activation: !hcv
              choices: *id001
              help: The activation function on the output of the layer.
              value: selu
            attention dropout_rate: !hcv
              help: The dropout rate for the attention layers of the transformer blocks.
              value: 0.25
            dense dropout_rate: !hcv
              help: The dropout rate for the dense layers of the transformer blocks.
              value: 0.25
            dims: !hcv
              help: The number of dimensions for the output.
              value: 64
            key_dims: !hcv
              help: Size of the attention head for query and key.
              value: 32
            num_heads: !hcv
              help: The number of separate heads of attention to use.
              value: 4
            num_hidden_dense: !hcv
              help: The number of hidden dense layers
              value: 2
            num_hidden_layers: !hcv
              help: Number of transformer blocks.
              value: 2
            output_dims: !hcv
              help: The number of output dimensions from this layer.
              value: 512
            use_bias: !hcv
              help: Use bias in the dense layers
              value: true
            value_dims: !hcv
              help: Size of the attention head for value.
              value: 32
        ItemDropout: !hcv
          help: Drops out entire items from the set.
          value: !hc
            rate: !hcv
              help: The percent of values that get replaced with zero.
              value: 0.2
        Pooling: !hcv
          help: The layer to collapse down to one embedding.
          value: !hc
            Attention: !hcv
              help: The attention layer that pools the results.
              value: !hc
                dropout: !hcv
                  help: The percent of values to get dropped out
                  value: 0.25
                key_dims: !hcv
                  help: Size of the attention head for query and key.
                  value: 8
                num_heads: !hcv
                  help: The number of separate heads of attention to use.
                  value: 8
                output_dims: !hcv
                  help: The number of output dimensions from this layer.
                  value: 64
                use_bias: !hcv
                  help: Use bias in the dense layers
                  value: true
                value_dims: !hcv
                  help: Size of the attention head for value.
                  value: 4
        decoding_dropout_rate: !hcv
          help: The percent of values to dropout from the result of dense layers in
            the decoding step.
          value: 0.1
    RatingFromPool: !hcv
      help: The layer that rates based on the other cards that have been picked.
      value: !hc
        EmbedContext: !hcv
          help: The Attentive set embedding layer to use if set_embed_type is 'attentive'
          value: !hc
            Decoder: !hcv
              help: The mapping from the added item embeddings to the embeddings to
                return.
              value: !hc
                Final: !hcv
                  help: The last dense layer in the MLP.
                  value: !hc
                    use_bias: !hcv
                      help: Whether to use bias on the output.
                      value: true
                Hidden_0: !hcv
                  help: The 1st hidden layer.
                  value: !hc
                    activation: !hcv
                      choices: *id001
                      help: The activation function on the output of the layer.
                      value: selu
                    dims: !hcv
                      help: The number of dimensions in the output of this layer.
                      value: 128
                    use_bias: !hcv
                      help: Whether to use bias on the output.
                      value: true
                num_hidden: !hcv
                  help: The number of hidden layers in the MLP.
                  value: 1
            Encoder: !hcv
              help: The layers to model interactions between items.
              value: !hc
                Transformer_0: !hcv
                  help: The 0th transformer layer.
                  value: !hc
                    FinalMLP: !hcv
                      help: The final transformation.
                      value: !hc
                        Final: !hcv
                          help: The last dense layer in the MLP.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 64
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_0: !hcv
                          help: The 1st hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 128
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_1: !hcv
                          help: The 2nd hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 256
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                Transformer_1: !hcv
                  help: The 1th transformer layer.
                  value: !hc
                    FinalMLP: !hcv
                      help: The final transformation.
                      value: !hc
                        Final: !hcv
                          help: The last dense layer in the MLP.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 64
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_0: !hcv
                          help: The 1st hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 128
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_1: !hcv
                          help: The 2nd hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 256
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                Transformer_2: !hcv
                  help: The 2th transformer layer.
                  value: !hc
                    FinalMLP: !hcv
                      help: The final transformation.
                      value: !hc
                        Final: !hcv
                          help: The last dense layer in the MLP.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 64
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_0: !hcv
                          help: The 1st hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 128
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_1: !hcv
                          help: The 2nd hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 256
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                activation: !hcv
                  choices: *id001
                  help: The activation function on the output of the layer.
                  value: selu
                attention dropout_rate: !hcv
                  help: The dropout rate for the attention layers of the transformer
                    blocks.
                  value: 0.25
                dense dropout_rate: !hcv
                  help: The dropout rate for the dense layers of the transformer blocks.
                  value: 0.25
                dims: !hcv
                  help: The number of dimensions for the output.
                  value: 64
                key_dims: !hcv
                  help: Size of the attention head for query and key.
                  value: 32
                num_heads: !hcv
                  help: The number of separate heads of attention to use.
                  value: 4
                num_hidden_dense: !hcv
                  help: The number of hidden dense layers
                  value: 2
                num_hidden_layers: !hcv
                  help: Number of transformer blocks.
                  value: 2
                output_dims: !hcv
                  help: The number of output dimensions from this layer.
                  value: 512
                use_bias: !hcv
                  help: Use bias in the dense layers
                  value: true
                value_dims: !hcv
                  help: Size of the attention head for value.
                  value: 32
            ItemDropout: !hcv
              help: Drops out entire items from the set.
              value: !hc
                rate: !hcv
                  help: The percent of values that get replaced with zero.
                  value: 0.2
            Pooling: !hcv
              help: The layer to collapse down to one embedding.
              value: !hc
                Attention: !hcv
                  help: The attention layer that pools the results.
                  value: !hc
                    dropout: !hcv
                      help: The percent of values to get dropped out
                      value: 0.25
                    key_dims: !hcv
                      help: Size of the attention head for query and key.
                      value: 8
                    num_heads: !hcv
                      help: The number of separate heads of attention to use.
                      value: 8
                    output_dims: !hcv
                      help: The number of output dimensions from this layer.
                      value: 64
                    use_bias: !hcv
                      help: Use bias in the dense layers
                      value: true
                    value_dims: !hcv
                      help: Size of the attention head for value.
                      value: 4
            decoding_dropout_rate: !hcv
              help: The percent of values to dropout from the result of dense layers
                in the decoding step.
              value: 0.1
        EmbedItem: !hcv
          help: Transforms the card embeddings to the embedding used to calculate
            distances.
          value: !hc
            Dropout: !hcv
              help: The dropout applied after each hidden layer.
              value: !hc
                rate: !hcv
                  help: The percent of values that get replaced with zero.
                  value: 0.2
            Final: !hcv
              help: The last dense layer in the MLP.
              value: !hc
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            Hidden_0: !hcv
              help: The 1st hidden layer.
              value: !hc
                activation: !hcv
                  choices: *id001
                  help: The activation function on the output of the layer.
                  value: selu
                dims: !hcv
                  help: The number of dimensions in the output of this layer.
                  value: 128
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            num_hidden: !hcv
              help: The number of hidden layers in the MLP.
              value: 1
        bounded_distance: !hcv
          help: Transform the distance to be in the range (0, 1)
          value: false
        final_activation: !hcv
          choices: *id001
          help: The final activation before calculating distance
          value: linear
        measure_dims: !hcv
          help: The number of dimensions to calculate distance in
          value: 64
        set_embed_type: !hcv
          choices: &id002 !!python/tuple
          - additive
          - attentive
          help: The kind of set embedding to use to get the context embedding for
            distance calculation.
          value: attentive
    RatingFromSeen: !hcv
      help: The layer that rates based on the embeddings of the packs that have been
        seen.
      value: !hc
        EmbedContext: !hcv
          help: The Attentive set embedding layer to use if set_embed_type is 'attentive'
          value: !hc
            Decoder: !hcv
              help: The mapping from the added item embeddings to the embeddings to
                return.
              value: !hc
                Final: !hcv
                  help: The last dense layer in the MLP.
                  value: !hc
                    use_bias: !hcv
                      help: Whether to use bias on the output.
                      value: true
                Hidden_0: !hcv
                  help: The 1st hidden layer.
                  value: !hc
                    activation: !hcv
                      choices: *id001
                      help: The activation function on the output of the layer.
                      value: selu
                    dims: !hcv
                      help: The number of dimensions in the output of this layer.
                      value: 128
                    use_bias: !hcv
                      help: Whether to use bias on the output.
                      value: true
                num_hidden: !hcv
                  help: The number of hidden layers in the MLP.
                  value: 1
            Encoder: !hcv
              help: The layers to model interactions between items.
              value: !hc
                Transformer_0: !hcv
                  help: The 0th transformer layer.
                  value: !hc
                    FinalMLP: !hcv
                      help: The final transformation.
                      value: !hc
                        Final: !hcv
                          help: The last dense layer in the MLP.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 64
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_0: !hcv
                          help: The 1st hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 128
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_1: !hcv
                          help: The 2nd hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 256
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                Transformer_1: !hcv
                  help: The 1th transformer layer.
                  value: !hc
                    FinalMLP: !hcv
                      help: The final transformation.
                      value: !hc
                        Final: !hcv
                          help: The last dense layer in the MLP.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 64
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_0: !hcv
                          help: The 1st hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 128
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_1: !hcv
                          help: The 2nd hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 256
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                Transformer_2: !hcv
                  help: The 2th transformer layer.
                  value: !hc
                    FinalMLP: !hcv
                      help: The final transformation.
                      value: !hc
                        Final: !hcv
                          help: The last dense layer in the MLP.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 64
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_0: !hcv
                          help: The 1st hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 128
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                        Hidden_1: !hcv
                          help: The 2nd hidden layer.
                          value: !hc
                            activation: !hcv
                              choices: *id001
                              help: The activation function on the output of the layer.
                              value: selu
                            dims: !hcv
                              help: The number of dimensions in the output of this
                                layer.
                              value: 256
                            use_bias: !hcv
                              help: Whether to use bias on the output.
                              value: true
                activation: !hcv
                  choices: *id001
                  help: The activation function on the output of the layer.
                  value: selu
                attention dropout_rate: !hcv
                  help: The dropout rate for the attention layers of the transformer
                    blocks.
                  value: 0.25
                dense dropout_rate: !hcv
                  help: The dropout rate for the dense layers of the transformer blocks.
                  value: 0.25
                dims: !hcv
                  help: The number of dimensions for the output.
                  value: 64
                key_dims: !hcv
                  help: Size of the attention head for query and key.
                  value: 32
                num_heads: !hcv
                  help: The number of separate heads of attention to use.
                  value: 4
                num_hidden_dense: !hcv
                  help: The number of hidden dense layers
                  value: 2
                num_hidden_layers: !hcv
                  help: Number of transformer blocks.
                  value: 2
                output_dims: !hcv
                  help: The number of output dimensions from this layer.
                  value: 512
                use_bias: !hcv
                  help: Use bias in the dense layers
                  value: true
                value_dims: !hcv
                  help: Size of the attention head for value.
                  value: 32
            ItemDropout: !hcv
              help: Drops out entire items from the set.
              value: !hc
                rate: !hcv
                  help: The percent of values that get replaced with zero.
                  value: 0.2
            Pooling: !hcv
              help: The layer to collapse down to one embedding.
              value: !hc
                Attention: !hcv
                  help: The attention layer that pools the results.
                  value: !hc
                    dropout: !hcv
                      help: The percent of values to get dropped out
                      value: 0.25
                    key_dims: !hcv
                      help: Size of the attention head for query and key.
                      value: 8
                    num_heads: !hcv
                      help: The number of separate heads of attention to use.
                      value: 8
                    output_dims: !hcv
                      help: The number of output dimensions from this layer.
                      value: 64
                    use_bias: !hcv
                      help: Use bias in the dense layers
                      value: true
                    value_dims: !hcv
                      help: Size of the attention head for value.
                      value: 4
            decoding_dropout_rate: !hcv
              help: The percent of values to dropout from the result of dense layers
                in the decoding step.
              value: 0.1
        EmbedItem: !hcv
          help: Transforms the card embeddings to the embedding used to calculate
            distances.
          value: !hc
            Dropout: !hcv
              help: The dropout applied after each hidden layer.
              value: !hc
                rate: !hcv
                  help: The percent of values that get replaced with zero.
                  value: 0.2
            Final: !hcv
              help: The last dense layer in the MLP.
              value: !hc
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            Hidden_0: !hcv
              help: The 1st hidden layer.
              value: !hc
                activation: !hcv
                  choices: *id001
                  help: The activation function on the output of the layer.
                  value: selu
                dims: !hcv
                  help: The number of dimensions in the output of this layer.
                  value: 128
                use_bias: !hcv
                  help: Whether to use bias on the output.
                  value: true
            num_hidden: !hcv
              help: The number of hidden layers in the MLP.
              value: 1
        bounded_distance: !hcv
          help: Transform the distance to be in the range (0, 1)
          value: false
        final_activation: !hcv
          choices: *id001
          help: The final activation before calculating distance
          value: linear
        measure_dims: !hcv
          help: The number of dimensions to calculate distance in
          value: 64
        set_embed_type: !hcv
          choices: *id002
          help: The kind of set embedding to use to get the context embedding for
            distance calculation.
          value: attentive
    item_ratings: !hcv
      help: Whether to give each card a rating independent of context.
      value: true
    log_loss_weight: !hcv
      help: The weight given to log_loss. Triplet loss weight is 1 - log_loss_weight
        - rating_stddev_weight
      value: 0.2
    margin: !hcv
      help: The margin by which we want the correct choice to beat the incorrect choices.
      value: 2
    pool_context_ratings: !hcv
      help: Whether to rate cards based on how the go with the other cards in the
        pool so far.
      value: true
    pool_variance_weight: !hcv
      help: The weight given to the variance of the pool contextual ratings.
      value: 0.01
    rating_variance_weight: !hcv
      help: The weight given to the variance of the card ratings.
      value: 0
    seen_context_ratings: !hcv
      help: Whether to rate cards based on the packs seen so far.
      value: true
    seen_pack_dims: !hcv
      help: The number of dimensions to embed seen packs into.
      value: 64
    seen_variance_weight: !hcv
      help: The weight given to the variance of the seen contextual ratings.
      value: 0.01
EmbedCards: !hcv
  help: The embeddings for the card objects.
  value: !hc
    dims: !hcv
      help: The number of dimensions the items should be embedded into.
      value: 64
    trainable: !hcv
      help: Whether the embeddings should be trained.
      value: true
adam_learning_rate: !hcv
  help: The learning rate to use for adam
  value: 0.0001
adj_mtx_batch_size: !hcv
  help: The number of rows of the adjacency matrices to evaluate at a time.
  value: 8
cube_adj_mtx_weight: !hcv
  help: The weight to multiply the cube adjacency matrix loss by.
  value: 0
cube_batch_size: !hcv
  help: The number of cube samples to evaluate at a time
  value: 4
cube_noise_mean: !hcv
  help: The median of the noise distribution for cubes.
  value: 0.4
cube_noise_std: !hcv
  help: The median of the noise distribution for cubes.
  value: 0.15
deck_adj_mtx_weight: !hcv
  help: The weight to multiply the deck adjacency matrix loss by.
  value: 8
draftbots_weight: !hcv
  help: The weight to multiply the draftbot loss by.
  value: 1
dtype: !hcv
  choices: !!python/tuple
  - 16
  - 32
  - 64
  help: The size of the floating point numbers to use for calculations in the model
  value: 32
epochs_for_completion: !hcv
  help: The number of epochs it should take to go through the entire dataset.
  value: 10
optimizer: !hcv
  choices: !!python/tuple
  - adam
  - adamax
  - adadelta
  - nadam
  - sgd
  - lazyadam
  - rectadam
  - novograd
  help: The optimizer type to use for optimization
  value: adam
pick_batch_size: !hcv
  help: The number of picks to evaluate at a time
  value: 64
recommender_weight: !hcv
  help: The weight to multiply the recommender loss by.
  value: 2
use_xla: !hcv
  help: Whether to use xla to speed up calculations.
  value: true
